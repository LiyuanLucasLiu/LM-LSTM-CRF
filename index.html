<!DOCTYPE html>
<html>

  <head>
    <meta charset='utf-8' />
    <meta http-equiv="X-UA-Compatible" content="chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
    <meta name="description" content="Empower Sequence Labeling with Task-Aware Language Model" />

    <link rel="stylesheet" type="text/css" media="screen" href="stylesheets/stylesheet.css">

    <link href='https://fonts.googleapis.com/css?family=Roboto:400,400italic,700italic,700' rel='stylesheet' type='text/css'>
    <link href='https://fonts.googleapis.com/css?family=Roboto+Condensed:300,300italic,700,700italic' rel='stylesheet' type='text/css'>

    <title>LM-LSTM-CRF</title>
  </head>

  <body>

    <!-- HEADER -->
    <div id="header_wrap" class="outer">
        <header class="inner">
          <a id="forkme_banner" href="https://github.com/LiyuanLucasLiu/LM-LSTM-CRF">View on GitHub</a>

          <h2 id="project_tagline">Empower Sequence Labeling with Task-Aware Language Model</h2>
            
          <h3 id="project_author">
          <a href="https://liyuanlucasliu.github.io/">Liyuan Liu</a>, <a href="http://shangjingbo1226.github.io/">Jingbo Shang</a>, <a href="http://frankxfz.me">Frank F. Xu</a>, <a href="http://xren7.web.engr.illinois.edu/">Xiang Ren</a>, <a href="http://huangui2.web.engr.illinois.edu/">Huan Gui</a>, <a href="http://jianpeng.web.engr.illinois.edu/">Jian Peng</a>, <a href="http://hanj.cs.illinois.edu/">Jiawei Han</a>
          </h3>
        </header>
    </div>

    <section class="outer">
      <div class="downloads inner">
        <a class="zip_download_link" href="https://arxiv.org/pdf/1709.04109.pdf">Paper</a>
        <a class="tar_download_link" href="#Ref">Bib Tex</a>
        <a class="zip_download_link" href="http://lm-lstm-crf.readthedocs.io/en/latest/">Documentation</a>
      </div>
      <p>
    </section>



    <!-- MAIN CONTENT -->
    <div id="main_content_wrap" class="outer">
      <section id="main_content" class="inner">
      <h1>Sequence Labeling</h1>
        <p>
          Linguistic sequence labeling is a general modeling approach that encompasses a variety of problems, such as <em>part-of-speech tagging</em> and <em>named entity recognition</em>.
        </p>

      <h1>Challenges</h1>
        <p>
          Recent advances in neural networks (NNs) make it possible to build reliable models without handcrafted features.
          However, in many cases, it is hard to obtain sufficient annotations to train these models.
        </p>


      <h1>Our Solution</h1>

      <p align="center"><img width="100%" alt="framework" src="docs/framework.png"/></p>

      <p>
        As visualized above, we use conditional random field (CRF) to capture label dependencies, and adopt a hierarchical LSTM to leverage both char-level and word-level inputs. 
        The char-level structure is further guided by a language model, while pre-trained word embeddings are leveraged in word-level. 
        The language model and the sequence labeling model are trained at the same time, and both make predictions at word-level.
        <a href="https://arxiv.org/abs/1507.06228">Highway networks</a> are used to transform the output of char-level LSTM into different semantic spaces, and thus mediating these two tasks and allowing language model to empower sequence labeling.
      </p>

      <h1>Experiments</h1>
        <p>
        Here we compare LM-LSTM-CRF with recent state-of-the-art models on the CoNLL 2000 Chunking dataset, the CoNLL 2003 NER dataset, and the WSJ portion of the PTB POS Tagging dataset. All experiments are conducted on a GTX 1080 GPU.
        </p>

        <h2>NER</h2>

        When models are only trained on the CoNLL 2003 English NER dataset, the results are summarized as below.

        <table align="center">
        <caption>Table. 1 Performance on the CoNLL 2003 NER dataset</caption>
        <tr>
          <th>Method</th>
          <th>Max(F1)</th> 
          <th>Mean(F1)</th>
          <th>Std(F1)</th>
          <th>Reported(F1)</th>
          <th>Time(h)</th>
        </tr>
        <tr>
          <td> <a href="www.aclweb.org/anthology/N16-1030">Lample et al. 2016</a> </td>
          <td> 91.14 </td>
          <td> 90.76 </td>
          <td> 0.08 </td>
          <td> 90.94 </td>
          <td> 46 </td>
        </tr>
        <tr>   
          <td> <a href="www.cs.cmu.edu/~xuezhem/publications/P16-1101.pdf">Ma et al. 2016</a> </td>
          <td> 91.67 </td>
          <td> 91.37 </td>
          <td> 0.17 </td>
          <td> 91.21 </td>
          <td> 7 </td>
        </tr>
        <tr>
          <td> LM-LSTM-CRF (our) </td>
          <td>  <b>91.85</b> </td>
          <td>  <b>91.71</b> </td>
          <td> 0.10 </td>
          <td> </td>
          <td> 6 </td>
        </tr>
        </table>

        <h2>POS</h2>

        When models are only trained on the WSJ portion of the PTB POS Tagging dataset, the results are summarized as below.

        <table align="center">
        <caption>Table. 2 Performance on the WSJ portion of the PTB POS Tagging dataset</caption>
        <tr>
          <th>Method</th>
          <th>Max(F1)</th> 
          <th>Mean(F1)</th>
          <th>Std(F1)</th>
          <th>Reported(F1)</th>
          <th>Time(h)</th>
        </tr>
        <tr>
          <td> <a href="www.aclweb.org/anthology/N16-1030">Lample et al. 2016</a> </td>
          <td> 97.51 </td>
          <td> 97.35 </td>
          <td> 0.09 </td>
          <td> </td>
          <td> 37 </td>
        </tr>
        <tr>   
          <td> <a href="www.cs.cmu.edu/~xuezhem/publications/P16-1101.pdf">Ma et al. 2016</a> </td>
          <td> 97.46 </td>
          <td> 97.42 </td>
          <td> 0.04 </td>
          <td> 97.55 </td>
          <td> 21 </td>
        </tr>
        <tr>
          <td> LM-LSTM-CRF (our) </td>
          <td> <b>97.59</b> </td>
          <td> <b>97.53</b> </td>
          <td> 0.03 </td>
          <td> </td>
          <td> 16 </td>
        </tr>
        </table>

        <h2>Chunking</h2>

        When models are only trained on the CoNLL 2000 Chunking dataset, the results are summarized as below.

        <table align="center">
        <caption>Table. 2 Performance on CoNLL00 Chunking task</caption>
        <tr>
          <th>Method</th>
          <th>Max(F1)</th> 
          <th>Mean(F1)</th>
          <th>Std(F1)</th>
          <th>Time(h)</th>
        </tr>
        <tr>
          <td> <a href="www.aclweb.org/anthology/N16-1030">Lample et al. 2016</a> </td>
          <td> 94.49 </td>
          <td> 94.37 </td>
          <td> 0.07 </td>
          <td> 26 </td>
        </tr>
        <tr>   
          <td> <a href="www.cs.cmu.edu/~xuezhem/publications/P16-1101.pdf">Ma et al. 2016</a> </td>
          <td> 95.93 </td>
          <td> 95.80 </td>
          <td> 0.13 </td>
          <td> 6 </td>
        </tr>
        <tr>
          <td> LM-LSTM-CRF (our) </td>
          <td> <b>96.13</b> </td>
          <td> <b>95.96</b> </td>
          <td> 0.08 </td>
          <td> 5 </td>
        </tr>
        </table>

      <h1 id="Ref">Bib Tex</h1>

      <p>
      Please cite the following paper if you find the codes and datasets useful.
      </p>

      <p id="reference">
      @inproceedings{2017arXiv170904109L,<br>
      &nbsp title = "{Empower Sequence Labeling with Task-Aware Neural Language Model}", <br>
      &nbsp author = {{Liu}, L. and {Shang}, J. and {Xu}, F. and {Ren}, X. and {Gui}, H. and {Peng}, J. and {Han}, J.}, <br>
      &nbsp booktitle = {AAAI}, <br>
      &nbsp year = 2017, <br>
      }</p>
      </section>
    </div>

    <!-- FOOTER  -->
    <div id="footer_wrap" class="outer">
      <footer class="inner">    
        <p>
          <a href="http://www.hitwebcounter.com" target="_blank">
          <img src="http://hitwebcounter.com/counter/counter.php?page=6766612&style=0006&nbdigits=8&type=page&initCount=0" title="hit counts" Alt="hit counts" border="0" >
          </a>                                           
        </p>
        <p class="copyright">by <a href="https://github.com/jasoncostello">Slate Theme</a></p>
        <p>Published with <a href="http://pages.github.com">GitHub Pages</a></p>
      </footer>
    </div>

  </body>
</html>
